{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "knT7akrcXs7K",
    "outputId": "a4c02238-90d9-4034-b2c8-a0682192ca0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(\"/content/drive/MyDrive/generative_inpaintingv2/checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "faBr4fXLsg55"
   },
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ttFLC21TpiBE"
   },
   "source": [
    "## Tf function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "TL1jDWu3plLt"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a model using low-level tf.* APIs\n",
    "# @tf.keras.utils.register_keras_serializable()\n",
    "class pre_process(tf.Module):\n",
    "  # def __init__(self,**kwargs):\n",
    "  #   super(pre_process, self).__init__(**kwargs)\n",
    "  \n",
    "  def __call__(self, raw_img, raw_mask, multiple,INPUT_SIZE):\n",
    "    # print(\"aaaa\")\n",
    "    raw_mask = raw_mask[:,:,:,0:1] / 255.\n",
    "    raw_img = raw_img\n",
    "\n",
    "    # resize raw image & mask to desinated size\n",
    "\n",
    "    large_size = multiple[0][0] * INPUT_SIZE[0][0]\n",
    "\n",
    "    large_img = tf.image.resize(raw_img ,[large_size, large_size],method = \"bilinear\" )\n",
    "    \n",
    "    large_mask = tf.image.resize(raw_mask ,[large_size, large_size],method = \"bilinear\" )\n",
    "\n",
    "\n",
    "    # down-sample large image & mask to 512x512\n",
    "    small_img = self.resize_ave(large_img, multiple,INPUT_SIZE)\n",
    "    small_mask = tf.image.resize(raw_mask ,[INPUT_SIZE[0][0], INPUT_SIZE[0][0]],method = \"nearest\" )\n",
    "\n",
    "    # # set hole region to 1. and backgroun to 0.\n",
    "   \n",
    "    small_img = tf.expand_dims(small_img,0)\n",
    "\n",
    "    return large_img, large_mask, small_img, small_mask\n",
    "  \n",
    "\n",
    "\n",
    "  \n",
    "  def resize_ave(self,img, multiple,INPUT_SIZE):\n",
    "    img_patches = self.extract_image_patches(img, multiple,INPUT_SIZE)\n",
    "    # img = np.mean(img_patches, axis=(2,3))\n",
    "    img = tf.reduce_mean(img_patches, axis=(2,3))\n",
    "    return img \n",
    "\n",
    "\n",
    "  def extract_image_patches(self,img, multiple,INPUT_SIZE):\n",
    "\n",
    "    img = tf.reshape(img,[INPUT_SIZE[0][0], multiple[0][0], INPUT_SIZE[0][0], multiple[0][0], 3])\n",
    "\n",
    "\n",
    "    img = tf.transpose(img, [0,2,1,3,4])\n",
    "    return img\n",
    "\n",
    "def Pre(shape ,new_shape):\n",
    "    input = [tf.keras.Input(shape=shape, dtype='float32'),tf.keras.Input(shape=new_shape, dtype='float32'),tf.keras.Input(shape=(1), dtype='float32'),tf.keras.Input(shape=(1), dtype='float32')]\n",
    "    large_img, large_mask, small_img, small_mask = pre_process()(input[0],input[1],input[2],input[3])\n",
    "    model = tf.keras.Model(inputs = input, outputs = [large_img, large_mask, small_img, small_mask])\n",
    "    return model\n",
    "  \n",
    "premodel = Pre(shape =(512,680,3),new_shape =(512,680,3))\n",
    "# (ro run your model) result = Squared(5.0) # This prints \"25.0\"\n",
    "# (to generate a SavedModel) tf.saved_model.save(model, \"saved_model_tf_dir\")\n",
    "# concrete_func = model.__call__.get_concrete_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q5CxxE6l7PH3",
    "outputId": "f0e40fc0-ebb2-4c65-fc93-69d55bbc9d16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 512, 680, 3) dtype=float32 (created by layer 'input_16')>,\n",
       " <KerasTensor: shape=(None, 512, 680, 3) dtype=float32 (created by layer 'input_17')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'input_18')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'input_19')>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "premodel.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Xh6whdTIrD7f"
   },
   "outputs": [],
   "source": [
    "class post_process(tf.Module):\n",
    "  def __call__(self, large_img, large_mask, res_512, img_512,mask_512, attention, multiple,INPUT_SIZE,ATTENTION_SIZE,width,height):\n",
    "\n",
    "    low_base = tf.image.resize(res_512 ,[multiple[0][0] * INPUT_SIZE[0][0], multiple[0][0] * INPUT_SIZE[0][0]],method = \"bilinear\" )\n",
    " \n",
    "    low_large = tf.image.resize(img_512 ,[multiple[0][0] * INPUT_SIZE[0][0], multiple[0][0] * INPUT_SIZE[0][0]],method = \"bilinear\" )\n",
    "\n",
    "    residual = (large_img - low_large) * large_mask\n",
    "\n",
    "    # reconstruct residual map using residual aggregation module\n",
    "    residual = self.residual_aggregate(residual, attention, multiple,INPUT_SIZE,ATTENTION_SIZE)\n",
    "\n",
    "    # compute large inpainted result\n",
    "    res_large = low_base + residual\n",
    "    # res_large = np.clip(res_large, 0., 255.)\n",
    "    res_large = tf.clip_by_value(res_large ,0.,255.)\n",
    "\n",
    "    # resize large inpainted result to raw size\n",
    "   \n",
    "    res_raw =tf.image.resize(res_large ,[width[0][0] , height[0][0]],method = \"bilinear\")\n",
    "    # paste the hole region to the original raw image\n",
    "    mask = tf.image.resize(mask_512 ,[width[0][0] , height[0][0]],method = \"bilinear\")\n",
    "\n",
    " \n",
    "\n",
    "    return res_raw , mask\n",
    "\n",
    "  def residual_aggregate(self,residual, attention, multiple,INPUT_SIZE,ATTENTION_SIZE):\n",
    "    \n",
    "    residual = self.extract_image_patches(residual, multiple ,INPUT_SIZE,ATTENTION_SIZE)\n",
    "    residual = tf.reshape(residual,[1,ATTENTION_SIZE[0][0]*ATTENTION_SIZE[0][0],-1])\n",
    "    \n",
    "    residual = tf.matmul(attention,residual)\n",
    "    \n",
    "    residual = self.reconstruct_residual_from_patches(residual, multiple ,INPUT_SIZE,ATTENTION_SIZE)\n",
    "    \n",
    "    return residual \n",
    "  \n",
    "\n",
    "  def extract_image_patches(self,img, multiple,INPUT_SIZE,ATTENTION_SIZE):\n",
    "   \n",
    "    size = multiple[0][0] * INPUT_SIZE[0][0]//ATTENTION_SIZE[0][0]\n",
    "    img = tf.reshape(img,[(INPUT_SIZE[0][0]*multiple[0][0])//size, size, (INPUT_SIZE[0][0]*multiple[0][0])//size, size, 3])\n",
    "\n",
    "    img = tf.transpose(img, [0,2,1,3,4])\n",
    "    return img\n",
    "  \n",
    "  def reconstruct_residual_from_patches(self,residual, multiple,INPUT_SIZE,ATTENTION_SIZE):\n",
    "    size = multiple[0][0] * INPUT_SIZE[0][0]//ATTENTION_SIZE[0][0]\n",
    "\n",
    "    residual = tf.reshape(residual,[ATTENTION_SIZE[0][0], ATTENTION_SIZE[0][0], size, size, 3])\n",
    "    \n",
    "    residual = tf.transpose(residual,[0,2,1,3,4])\n",
    "    return tf.reshape(residual, [ATTENTION_SIZE[0][0] * size, ATTENTION_SIZE[0][0] * size, 3])\n",
    "   \n",
    "\n",
    "def Post(new_shape1,new_shape2,new_shape3,new_shape4,new_shape5):\n",
    "    input = [tf.keras.Input(shape=new_shape1, dtype='float32'),tf.keras.Input(shape=new_shape2, dtype='float32'),tf.keras.Input(shape=new_shape3, dtype='float32'),tf.keras.Input(shape=new_shape3, dtype='float32'),tf.keras.Input(shape=new_shape4, dtype='float32'),tf.keras.Input(shape=new_shape5, dtype='float32'),tf.keras.Input(shape=(1), dtype='float32'),tf.keras.Input(shape=(1), dtype='float32'),tf.keras.Input(shape=(1), dtype='float32'),tf.keras.Input(shape=(1), dtype='float32'),tf.keras.Input(shape=(1), dtype='float32')]\n",
    "    raw_image = post_process()(input[0],input[1],input[2],input[3],input[4],input[5],input[6],input[7],input[8],input[9],input[10])\n",
    "    model = tf.keras.Model(inputs = input, outputs = raw_image)\n",
    "    return model\n",
    "postmodel = Post(new_shape1 = (512,512,3) ,new_shape2 = (512,512,1) , new_shape3 = (256,256,3),new_shape4 = (256,256,1) , new_shape5 = (32,32,1024) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uXiaQqucgND5"
   },
   "outputs": [],
   "source": [
    "postmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDIPj7vGzqOa"
   },
   "source": [
    "##Pre process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "sFrRbHMRzpdt"
   },
   "outputs": [],
   "source": [
    "premodel.input[0].set_shape([1, 512, 680, 3])\n",
    "premodel.input[1].set_shape([1, 512, 680, 3])\n",
    "premodel.input[2].set_shape( [1,1])\n",
    "premodel.input[3].set_shape( [1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ZU5xObo2B6p"
   },
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(premodel)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "converter.allow_custom_ops = True\n",
    "converter.experimental_new_converter = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oKTsZha02DC4"
   },
   "outputs": [],
   "source": [
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_wXOsXW2E7z"
   },
   "outputs": [],
   "source": [
    "with open('./pre_process.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JNz1QMrw0U_"
   },
   "source": [
    "## Post process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "t813HcB8wz2v"
   },
   "outputs": [],
   "source": [
    "# model.input[0].set_shape([1, 512, 680, 3])\n",
    "postmodel.input[0].set_shape([1, 512, 512, 3])\n",
    "postmodel.input[1].set_shape( [1, 512, 512, 1])\n",
    "postmodel.input[2].set_shape( [1, 256, 256, 3])\n",
    "postmodel.input[3].set_shape(  [1, 256, 256, 3])\n",
    "postmodel.input[4].set_shape( [1, 256, 256, 1])\n",
    "postmodel.input[5].set_shape( [1, 32, 32, 1024])\n",
    "postmodel.input[6].set_shape( [1, 1])\n",
    "postmodel.input[7].set_shape( [1, 1])\n",
    "postmodel.input[8].set_shape( [1, 1])\n",
    "postmodel.input[9].set_shape( [1, 1])\n",
    "postmodel.input[10].set_shape( [1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "52QhrRp-w-_C"
   },
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(postmodel)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "converter.allow_custom_ops = True\n",
    "converter.experimental_new_converter = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f90JyUeVxB7d",
    "outputId": "2a858806-fb05-4734-82a6-6c0bfa4c9b44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmppwvx0ern/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmppwvx0ern/assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    }
   ],
   "source": [
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7jhFYE7IxGEo"
   },
   "outputs": [],
   "source": [
    "with open('./post_process_fix_mask.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "TrSjaIsU45zx",
    "9Lx7ll5YRFMP"
   ],
   "machine_shape": "hm",
   "name": "pre and post process.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
